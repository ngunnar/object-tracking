{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Convolution Operations\n",
    "\n",
    "## Background\n",
    "### Discriminative Correlation Filters (DCF)\n",
    "\n",
    "DCF methods train a correlation filter for the task of predicting the target classification scores. Unlike other methods, the DCF efficiently utilize all spatial shifts of the training samples by exploiting the discrete Fourier transform.\n",
    "\n",
    "The conventaional DCF formulation is limited to a single-resolution feature map. Therefore, all feature channels must have teh same spatial resolution.\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "E(f) = \\sum_{j=1}^m \\alpha_j || S_f\\{x_j\\} - y_j ||^2 + \\sum_{d=1}^D||\\omega f^d||^2\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep convolutional neural network (CNN)\n",
    "\n",
    "CNN have shown impressing performance for many tasks, and are therefore of interest for DCF-based tracking. A CNN consists of several layers of convolution, normalization and pooling operations. Recently, activations from the last convolutional layers hace been successfully employed for image classification. Features from these deep convolutional layers are discriminative while preserving spatial and structural information. Recent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Continuous Convolution Operators\n",
    "\n",
    "### Formulation\n",
    "\n",
    "The aim is to train a continuous convolution operator based on training examples $x_j$. The samples consist of feature maps extracted from image patches. Each sample $x_j$ contains $D$ feature channels, $x_j^1, ... , x_j^D$, extracted from the same image patch. Conventional DCF formulations assume the feature channels th have the same spatial resolution, i.e have teh same number of spatial sample points. Unlike previous work, we eliminate the restriction in our formulation and let $N_d$ denote the number of spatial samples in $x_j^d$. In our formulation, the feature channel $x_j^d \\in \\mathbb{R}^{N_d}$ is viewed as a function $x_j^d[n]$ indexed by the discrete spatial variable $n \\in \\{0,...N_d-1\\}$. The sample space is expressed as $\\chi = \\mathbb{R}^{N_1} \\times ... \\times \\mathbb{R}^{D}$.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
